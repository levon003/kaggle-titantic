---
title: "Data Preparation"
author: "Zachary Levonian"
date: "11/02/2018"
output: pdf_document
bibliography: "titanic kaggle project.bib"
csl: acm-sigchi-proceedings.csl
---

```{r}
library(alr4)
library(mice)  # for multiple imputation
library(BaylorEdPsych)  # For Little's MCAR test
library(polycor)  # To compute correlation between heterogenous variables
library(plotrix)  # For side-along histograms
```

# Load data

```{r}
train <- read.csv("../../data/raw/train.csv", stringsAsFactors=FALSE, na.strings = c("NA", ""))
test <- read.csv("../../data/raw/test.csv", stringsAsFactors=FALSE, na.strings = c("NA", ""))
```

Combine the data into a single dataframe to make it easier to work with.  I denote data in the test set with `Survived = 2`.

```{r}
test$Survived = 2
df <- rbind(train, test)
```

# Data exploration

## Build factors from data

```{r}
df$fSex = factor(df$Sex)
df$fEmbarked = factor(df$Embarked)
```

## High-level summaries and visualization

```{r}
pairs(df[c("fSex", "fEmbarked", "Pclass", "Age", "SibSp", "Parch", "Fare", "Survived")])
```

## Missing data

```{r}
sapply(df, function(x) sum(is.na(x)))
```

It looks like the only data that's missing is Age and Cabin data. In addition, a single instance of the missing Fare data (in the test set) and two instances of the Embarked data are missing.

### Fare missing data

```{r}
# print the row where Fare info is missing
df[is.na(df["Fare"])]
```

We need to impute this value, but as there's only a single missing value it's impossible to determine if the data is missing at random or not.

We will assume the data is missing at random and impute a value for Thomas Storey's fare using `mice`.

It is imputed alongside the Age data below.

```{r}
#TODO use mice to impute the data
```

### fEmbarked missing data

Is imputed alongside the Age data below.

### Age missing data

263 passengers (20%) are missing age data.

First, we want to determine if the data are missing at random (MAR) or completely at random (MCAR).

```{r}
age_little_df <- df[,c("fSex", "fEmbarked", "Pclass", "Age", "SibSp", "Parch", "Survived")]
mcar <- LittleMCAR(age_little_df)
mcar$missing.patterns
mcar$amount.missing
mcar$p.value
```

Little's MCAR test generates a test statistic against the null hypothesis that the missing data are MCAR.  Thus, we have evidence that we ought to reject the null hypothesis and the missing age data are MAR @enders_applied_2010.

```{r}
age_little_df <- df[,c("fSex", "fEmbarked", "Pclass", "SibSp", "Parch", "Fare", "Survived")]
age_little_df$AgeMissing = as.numeric(is.na(df["Age"]))
hetcor(age_little_df)
```

A missing age value is correlated positively with passenger class ($r=0.2082$) and negatively with point of embarkment ($r=-0.1672$) and passenger fare ($r=-0.1306$).  All other correlations are < 0.1.  

I'm inclined to think that the true mediator of missing age (among the covariates in the dataset) is passenger class, which embarkment and fare both correlate with.

```{r}
t.test(df[is.na(df["Age"]),"Fare"], df[!is.na(df["Age"]),"Fare"])
```

We use a univariate $t$-test to evaluate the fare, since it's numeric, and at the 99% confidence level we reject the null hypothesis which suggests the missing data are MAR (rather than MCAR).

Now, we turn to tangible estimation of the missing data estimates.

```{r}
age_df <- df[,c("Age", "fSex", "fEmbarked", "Pclass", "SibSp", "Parch", "Fare", "Survived")]
imp <- mice(age_df, print=FALSE, m=20, seed=1, maxit=20)
imputed_df <- complete(imp)

#plot(imp)
#fit <- with(imp, lm(Survived ~ Age))
#pool(fit)
```

```{r}
# plot of the change in the distribution of Age 
# after imputation of NA values
multhist(list(imp$data$Age, complete(imp)$Age))
```


Following the guidance of @buuren_flexible_2018, we utilize multiple imputation with $m=20$ imputations.

TODO I should compare the performance of models where Age is imputed vs when it is removed via complete case analysis.

### Cabin missing data

I choose not to handle the Cabin data right now, since I think it needs a more elaborate extraction into multiple additional columns.

We could add a binary indicator variable for the presence of Cabin, but such indicator variables can result in biased regression estimates @buuren_flexible_2018.

### Overwrite the original dataframe with the imputed values

```{r}
df$fEmbarked <- imputed_df$fEmbarked
df$Age <- imputed_df$Age
df$Fare <- imputed_df$Fare
sapply(df, function(x) sum(is.na(x)))
```


## Save the cleaned-up data

Now, we save all the columns to be used as potential features to a file.

```{r}
toWrite <- df[,c("PassengerId", "fSex", "fEmbarked", "Pclass", "Age", "SibSp", "Parch", "Fare", "Survived")]
write.table(toWrite, file="../../data/derived/factorized_data.csv",
            row.names=FALSE, col.names=TRUE, 
            sep=",", quote=FALSE)
```

# Train a Model

The code below demonstrates:
 - Reading in the features
 - Splitting the data into the training and test data
 - Training a regression model
 - Predicting the test set based on the trained model
 - Saving the predictions in the Kaggle format for submission

```{r}
df <- read.csv("../../data/derived/factorized_data.csv", stringsAsFactors=TRUE)

```


```{r}
train <- df[df$Survived != 2, ]
test <- df[df$Survived == 2, ]
```

```{r}
md <- glm(Survived ~ fSex + fEmbarked + Pclass + Age + SibSp + Parch + Fare, family="binomial", data=train)
summary(md)
```


```{r}
# predict on the test set
y_pred <- predict(md, test, type="response")
hist(y_pred)
```

```{r}
# save the predictions to a file that can be submitted to Kaggle
test$Survived = as.numeric(y_pred > 0.5)
# while there shouldn't be NAs in the test output, 
# here we apply a nasty hack to ensure any NAs are numeric in the output
test[is.na(test)] <- 0
toWrite <- test[,c("PassengerId", "Survived")]
write.table(toWrite, file="../../data/derived/testModelPredictions.csv", 
            row.names=FALSE, col.names=TRUE, 
            sep=",", quote=FALSE)
```

# References
