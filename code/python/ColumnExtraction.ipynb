{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Extraction for Titanic Dataset\n",
    "===\n",
    "\n",
    "Derives a few potentially interesting variables from the existing raw data.\n",
    "\n",
    "Writes out the new columns to a separate sheet for later merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../data/raw/train.csv\")\n",
    "test = pd.read_csv(\"../../data/raw/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Survived\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1782"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat((train, test))\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticket Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           A/5 21171\n",
       "1            PC 17599\n",
       "2    STON/O2. 3101282\n",
       "3              113803\n",
       "4              373450\n",
       "5              330877\n",
       "6               17463\n",
       "7              349909\n",
       "8              347742\n",
       "9              237736\n",
       "Name: Ticket, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickets = df[\"Ticket\"]\n",
    "tickets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = list(tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weird tix: multiple parts STON/O 2. 3101294\n",
      "Weird tix: multiple parts STON/O 2. 3101280\n",
      "Weird tix: multiple parts STON/O 2. 3101275\n",
      "Weird tix: multiple parts STON/O 2. 3101293\n",
      "Weird tix: multiple parts STON/O 2. 3101289\n",
      "Weird tix: multiple parts STON/O 2. 3101269\n",
      "Weird tix: multiple parts STON/O 2. 3101274\n",
      "Weird tix: multiple parts SC/AH Basle 541\n",
      "Weird tix: multiple parts STON/O 2. 3101286\n",
      "Weird tix: multiple parts STON/O 2. 3101273\n",
      "Weird tix: multiple parts STON/O 2. 3101292\n",
      "Weird tix: multiple parts STON/O 2. 3101285\n",
      "Weird tix: multiple parts STON/O 2. 3101288\n",
      "Weird tix: multiple parts STON/O 2. 3101294\n",
      "Weird tix: multiple parts STON/O 2. 3101280\n",
      "Weird tix: multiple parts STON/O 2. 3101275\n",
      "Weird tix: multiple parts STON/O 2. 3101293\n",
      "Weird tix: multiple parts STON/O 2. 3101289\n",
      "Weird tix: multiple parts STON/O 2. 3101269\n",
      "Weird tix: multiple parts STON/O 2. 3101274\n",
      "Weird tix: multiple parts SC/AH Basle 541\n",
      "Weird tix: multiple parts STON/O 2. 3101286\n",
      "Weird tix: multiple parts STON/O 2. 3101273\n",
      "Weird tix: multiple parts STON/O 2. 3101292\n",
      "Weird tix: multiple parts STON/O 2. 3101285\n",
      "Weird tix: multiple parts STON/O 2. 3101288\n"
     ]
    }
   ],
   "source": [
    "tix_cats = []\n",
    "for ticket in tickets:\n",
    "    if ticket.isdigit():\n",
    "        tix_cat = \"digit\"\n",
    "        tix_cats.append(tix_cat)\n",
    "        continue\n",
    "    parts = ticket.split(\" \")\n",
    "    if len(parts) > 2:\n",
    "        print(\"Weird tix: multiple parts\", ticket)\n",
    "    if len(parts) == 2:\n",
    "        if not parts[1].isdigit():\n",
    "            print(\"Weird tix: non-digit\", ticket)\n",
    "    if len(parts) == 1:\n",
    "        tix_cat = parts[0]\n",
    "    else:\n",
    "        tix_cat = \" \".join(parts[:-1])\n",
    "    tix_cat = tix_cat.replace(\".\", \"\")\n",
    "    if tix_cat == \"\":\n",
    "        print(\"Weird tix: no digit\", ticket)\n",
    "    tix_cats.append(tix_cat)\n",
    "df[\"ticket_category\"] = tix_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('digit', 1322),\n",
       " ('PC', 120),\n",
       " ('CA', 82),\n",
       " ('A/5', 38),\n",
       " ('SOTON/OQ', 30),\n",
       " ('STON/O 2', 24),\n",
       " ('W/C', 20),\n",
       " ('SC/PARIS', 14),\n",
       " ('STON/O2', 12),\n",
       " ('A/4', 12),\n",
       " ('SOC', 10),\n",
       " ('C', 10),\n",
       " ('FCC', 10),\n",
       " ('SC/Paris', 8),\n",
       " ('LINE', 8),\n",
       " ('PP', 6),\n",
       " ('SO/PP', 6),\n",
       " ('A5', 4),\n",
       " ('SW/PP', 4),\n",
       " ('P/PP', 4),\n",
       " ('SC/AH', 4),\n",
       " ('WE/P', 4),\n",
       " ('SOTON/O2', 4),\n",
       " ('SC/A4', 2),\n",
       " ('SP', 2),\n",
       " ('SO/C', 2),\n",
       " ('WEP', 2),\n",
       " ('A4', 2),\n",
       " ('SOP', 2),\n",
       " ('Fa', 2),\n",
       " ('SCO/W', 2),\n",
       " ('SC', 2),\n",
       " ('A/S', 2),\n",
       " ('SC/AH Basle', 2),\n",
       " ('FC', 2),\n",
       " ('CA/SOTON', 2)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tix_cat_counts = Counter(tix_cats).most_common()\n",
    "tix_cat_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run some consolidation of categories...\n",
    "#TODO Identify which columns should actually be merged!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/levon003/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# consolidate lower-count cabin letters into a single factor level\n",
    "threshold = 7\n",
    "drop_low_counts = False  # should we drop low counts, or generate a new factor?\n",
    "new_tix_cat = None if drop_low_counts else \"other\"\n",
    "for tix_cat, count in tix_cat_counts:\n",
    "    if count < threshold:\n",
    "        df[\"ticket_category\"][df[\"ticket_category\"] == tix_cat] = new_tix_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('digit', 1322),\n",
       " ('PC', 120),\n",
       " ('CA', 82),\n",
       " ('other', 62),\n",
       " ('A/5', 38),\n",
       " ('SOTON/OQ', 30),\n",
       " ('STON/O 2', 24),\n",
       " ('W/C', 20),\n",
       " ('SC/PARIS', 14),\n",
       " ('STON/O2', 12),\n",
       " ('A/4', 12),\n",
       " ('SOC', 10),\n",
       " ('C', 10),\n",
       " ('FCC', 10),\n",
       " ('SC/Paris', 8),\n",
       " ('LINE', 8)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df[\"ticket_category\"]).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cabin Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     NaN\n",
       "1     C85\n",
       "2     NaN\n",
       "3    C123\n",
       "4     NaN\n",
       "5     NaN\n",
       "6     E46\n",
       "7     NaN\n",
       "8     NaN\n",
       "9     NaN\n",
       "Name: Cabin, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Cabin\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(nan, 1374),\n",
       " ('G6', 8),\n",
       " ('C23 C25 C27', 8),\n",
       " ('B96 B98', 8),\n",
       " ('F33', 6),\n",
       " ('E101', 6),\n",
       " ('F2', 6),\n",
       " ('D', 6),\n",
       " ('C22 C26', 6),\n",
       " ('C123', 4),\n",
       " ('D33', 4),\n",
       " ('C52', 4),\n",
       " ('B28', 4),\n",
       " ('C83', 4),\n",
       " ('F G73', 4),\n",
       " ('D26', 4),\n",
       " ('B58 B60', 4),\n",
       " ('C2', 4),\n",
       " ('E33', 4),\n",
       " ('F4', 4)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df[\"Cabin\"]).most_common()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_letters = []\n",
    "for cabin in df[\"Cabin\"]:\n",
    "    if cabin is None:\n",
    "        cabin_letters.append(\"n\")\n",
    "    else:\n",
    "        cabin = str(cabin)\n",
    "        cabin_letters.append(cabin[0])\n",
    "        # Taking the first letter is generally safe, although there are a few entries with multiple letter types\n",
    "df[\"cabin_first_letter\"] = cabin_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n', 1374),\n",
       " ('C', 118),\n",
       " ('B', 94),\n",
       " ('D', 66),\n",
       " ('E', 64),\n",
       " ('A', 30),\n",
       " ('F', 26),\n",
       " ('G', 8),\n",
       " ('T', 2)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cabin_letter_counts = Counter(df[\"cabin_first_letter\"]).most_common()\n",
    "cabin_letter_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/levon003/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# consolidate lower-count cabin letters into a single factor level\n",
    "threshold = 40\n",
    "drop_low_counts = False  # should we drop low counts, or generate a new factor?\n",
    "new_cabin_letter = \"n\" if drop_low_counts else \"o\"\n",
    "for cabin_letter, count in cabin_letter_counts:\n",
    "    if count < threshold:\n",
    "        df[\"cabin_first_letter\"][df[\"cabin_first_letter\"] == cabin_letter] = new_cabin_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n', 1374), ('C', 118), ('B', 94), ('o', 66), ('D', 66), ('E', 64)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cabin_letter_counts = Counter(df[\"cabin_first_letter\"]).most_common()\n",
    "cabin_letter_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              Braund, Mr. Owen Harris\n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...\n",
       "2                               Heikkinen, Miss. Laina\n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)\n",
       "4                             Allen, Mr. William Henry\n",
       "5                                     Moran, Mr. James\n",
       "6                              McCarthy, Mr. Timothy J\n",
       "7                       Palsson, Master. Gosta Leonard\n",
       "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\n",
       "9                  Nasser, Mrs. Nicholas (Adele Achem)\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Name\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_word_lengths = []\n",
    "name_char_lengths = []\n",
    "name_titles = []\n",
    "\n",
    "raw_name_titles = []\n",
    "# Based on a quick historic assessment of the use of these honorifics,\n",
    "# I mapped passenger titles to sub-categories\n",
    "name_title_map = {\n",
    "    \"Ms.\": \"Miss.\",\n",
    "    \"Mlle.\": \"Miss.\",\n",
    "    \"Major.\": \"Military\",\n",
    "    \"Col.\": \"Military\",\n",
    "    \"Capt.\": \"Military\",\n",
    "    \"Don.\": \"Nobility\",\n",
    "    \"Mme.\": \"Mrs.\",\n",
    "    \"Lady.\": \"Nobility\",\n",
    "    \"Sir.\": \"Nobility\",\n",
    "    \"Countess.\": \"Nobility\",\n",
    "    \"Jonkheer.\": \"Nobility\",\n",
    "}\n",
    "\n",
    "for name in df[\"Name\"]:\n",
    "    new_name = re.sub(\n",
    "           r\"\\(.+\\)\", \n",
    "           \"\", \n",
    "           name)\n",
    "    name_parts = new_name.split(\" \")\n",
    "    title_found = False\n",
    "    for name_part in name_parts:\n",
    "        if \".\" in name_part:\n",
    "            title_found = True\n",
    "            raw_name_titles.append(name_part)\n",
    "            title = name_part\n",
    "            if title in name_title_map:\n",
    "                title = name_title_map[title]\n",
    "            name_titles.append(title)\n",
    "            \n",
    "    name_length = len(name_parts)\n",
    "    if title_found:\n",
    "        name_length -= 1\n",
    "    if name_length >= 5:\n",
    "        # Count all names as 5+ words as 5 words\n",
    "        name_length = 5\n",
    "    name_word_lengths.append(name_length)\n",
    "    \n",
    "    #Length of the name without spaces, not including the title, minus 1 for the comma\n",
    "    char_length = len(\"\".join([np for np in name_parts if \".\" not in np])) - 1\n",
    "    name_char_lengths.append(char_length)\n",
    "    \n",
    "df[\"name_word_length\"] = name_word_lengths\n",
    "df[\"name_char_length\"] = name_char_lengths\n",
    "df[\"name_title\"] = name_titles\n",
    "df[\"name_title_raw\"] = raw_name_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mr.', 1034),\n",
       " ('Miss.', 364),\n",
       " ('Mrs.', 250),\n",
       " ('Master.', 80),\n",
       " ('Dr.', 14),\n",
       " ('Rev.', 12),\n",
       " ('Major.', 4),\n",
       " ('Mlle.', 4),\n",
       " ('Col.', 4),\n",
       " ('Don.', 2),\n",
       " ('Mme.', 2),\n",
       " ('Ms.', 2),\n",
       " ('Lady.', 2),\n",
       " ('Sir.', 2),\n",
       " ('Capt.', 2),\n",
       " ('Countess.', 2),\n",
       " ('Jonkheer.', 2)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(raw_name_titles).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mr.', 1034),\n",
       " ('Miss.', 370),\n",
       " ('Mrs.', 252),\n",
       " ('Master.', 80),\n",
       " ('Dr.', 14),\n",
       " ('Rev.', 12),\n",
       " ('Nobility', 10),\n",
       " ('Military', 10)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(name_titles).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 862), (2, 628), (4, 264), (5, 28)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df[\"name_word_length\"]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick histogram of the character lengths of names\n",
    "plt.hist(df[\"name_char_length\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = df[[\"PassengerId\",\n",
    "               \"ticket_category\", \"cabin_first_letter\", \"name_title\", \n",
    "               \"name_title_raw\", \"name_word_length\", \"name_char_length\"]]\n",
    "output_filepath = \"../../data/derived/levon003_new_cols.csv\"\n",
    "subset_df.to_csv(output_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
